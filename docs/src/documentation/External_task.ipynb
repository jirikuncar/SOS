{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executing external tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A complex workflow usually have a large number of steps, most of them are light-weight and can be executed locally, but some of them can be time- and resource-consuming and would better be executed on dedicated servers or cluster systems. There are several approaches in running such workflows, namely,\n",
    "\n",
    "1. Execute the entire workflow on the cluster as a single multi-processing job. This is not ideal because 1). you would have to allocate enough resource for the most CPU and RAM-demanging step and longest execution time for the most time-consuming step but these resources are not utilized efficiently, and 2). you are limiting yourself to a single node and cannot really execute the workflow in parallel.\n",
    "\n",
    "2. Separate the workflow by steps and submit them as separate tasks to a queuing system. This approach allows better parallelization but it can be difficult and time consuming to execute a large number of small jobs, because these tasks might spend more time waiting than running. \n",
    "\n",
    "3. Running a workflow on a cluster system requires a running server (task dispatcher, corrdinator) to corrdinate the execution of dependent steps. This has posed a problem, at least to our clusters because such processes are not allowed on the head node.\n",
    "\n",
    "To address these problems, SoS taks a different approach than mose other workflow systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## SoS' task model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Complete workflow\n",
    "\n",
    "SoS defines workflows as steps to execute certain procedures on input files (forward-style), or as steps to produce desired outputs (makefile style). All steps, regardless of their sizes (requirement for resources), are written as a single workflow. That is to say, a long running sequence alignment step and the relatively quick statistical analysis steps would be defined as a single workflow. **steps are not separated because of their different hardware/software requirements**.\n",
    "\n",
    "SoS executes all steps directly as a complete workflow. The workflow is executed in a multi-processing manner where multiple processes (by default to 4) are used to execute different branches of the DAG (Direct Acyclic Graph) in parallel.\n",
    "\n",
    "### Generation of external tasks\n",
    "\n",
    "Part of the steps can be defined as tasks that are executed externally. SoS tasks have the following properties:\n",
    "\n",
    "* **Tasks are self-contained** in that they contain all the required information to be executed anywhere. \n",
    "* **Tasks are generated and executed dynamically** in that a task would only be generated when all its dependencies have been met.\n",
    "* **Tasks are independent of workflows and other tasks**. Tasks are defined by the task they are executing. Tasks can be shared by different workflows if they happen to perform exactly the same function.\n",
    "* **Tasks are file system independent** in the sense that sos automatically synchronize input and output of tasks to remote systems so you can easily switch from a remote server to another, or to a cluster system.\n",
    "\n",
    "### Remote execution of tasks\n",
    "\n",
    "SoS tasks can be executed locally as separate  processes, remotely on a remote server, sent to distributed task-queues (such as [rq](http://python-rq.org/) or [Celery](http://www.celeryproject.org/), or cluster systems based on PBS, Torch, or SunGrid. SoS handles file synchronization so **tasks could be submitted to queues with their own file systems**. \n",
    "\n",
    "### Stop-and-resume execution of workflow\n",
    "\n",
    "SoS can wait for the completion of the tasks as if they are just long-running jobs executed locally. Alternatively, sos could exit and wait for the completion of external tasks. Command `sos status` or task-queue-specific methods could be used to monitor the execution of tasks.\n",
    "\n",
    "After the completion of the tasks, you could rerun the workflow and SoS would resume execution from the point where it was stopped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Flexible design of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "This external execution model offers great flexibility in the execution of workflows. For example,\n",
    "* You can execute a step on a remote server with more resource by specifying parameter `queue` of a single task.\n",
    "* You can submit all tasks of a workflow to a cluster by specifying cluster name with the `-q` option of command `sos run`.\n",
    "* You can submit part of the tasks to one machine, and part of the tasks to another task queue using the combination of task-specific option and global `-q` option.\n",
    "* You can use SoS as a task-generation tool to generate a bunch of tasks, and send the tasks to different computer systems for execution. SoS automatically handles file synchronization so that you can easily move from one cluster to another cluster or another server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The following figure illustrates the task model of SoS\n",
    "\n",
    "![job queue](../media/job_queue.svg )\n",
    "\n",
    "Basically,\n",
    "1. Tasks are part of step processes.\n",
    "2. Tasks are managed by task engines, multiple task engines can be used for a single workflow.\n",
    "3. Task engines generate task files, submit tasks, monitor task status, and return results to SoS workflow.\n",
    "4. Remote task engines synchronize input files, translate and copy tasks to server, and start the tasks on the remote server. Pre-defined `submit_cmd` could be used to submit tasks to batch systems such as PBS/Moab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Specification of tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **step process** consists of everything after the `input` statement. It can be repeated with different **input groups** defined by input options `group_by` or `for_each`. For example, if `bam_files` is a list of bam files,\n",
    "\n",
    "```\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: \"${_input}.bai\"\n",
    "\n",
    "run:\n",
    "    samtools index ${_input}\n",
    "```\n",
    "\n",
    "execute a shell script to process each bam file. This is done sequentially for each input file, and is performed by SoS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily specify part of the step process as **tasks**, by prepending the statements with a `task` keyword:\n",
    "\n",
    "\n",
    "```\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: \"${_input}.bai\"\n",
    "\n",
    "task:\n",
    "run:\n",
    "    samtools index ${_input}\n",
    "```\n",
    "\n",
    "This statement declares the rest of the step process as a `task`. For each input file, a task will be created with an ID determined from task content and context (input and output files, variables etc). The task will be by default executed by a `process` task queue where tasks are started as background processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of executing tasks externally is that you can execute tasks concurrently, on the local machine or a remote server, or be submitted to a task queue. For example, using\n",
    "\n",
    "```\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: \"${_input}.bai\"\n",
    "\n",
    "task: concurrent=True\n",
    "run:\n",
    "    samtools index ${_input}\n",
    "```\n",
    "\n",
    "Multiple tasks could be executed in parallel (but on the same machine), and you can use command\n",
    "\n",
    "```\n",
    "sos run myscript -q cluster\n",
    "```\n",
    "or use option `queue`\n",
    "```\n",
    "[10]\n",
    "input: bam_files, group_by=1\n",
    "output: \"${_input}.bai\"\n",
    "\n",
    "task: concurrent=True, queue='cluster'\n",
    "run:\n",
    "    samtools index ${_input}\n",
    "```\n",
    "\n",
    "to submit the commands to a cluster system to be executed on different computing nodes.\n",
    "\n",
    "This document focuses on the configuration of servers and the use of task options to execute tasks on different types of servers or task queues. It provides a comprehensive list of options while the [Remote Execution tutorial](../tutorials/Remote_Execution.html) gives a more step-by-step tutorial on how to configure and use the remote execution features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Common host configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "A server or task queue needs to be defined in SoS configuration file. SoS automatically loads a global configuration file `~/.sos/config.yml`, and a local configuration file `./config.yml`. You can also put your settings in any configuration file and specify it with option `-c`. We recommend that you define all host configuration in global configuration file `~/.sos/config.yml` so that it can be used by all your projects.\n",
    "\n",
    "The configuration file could be edited manually if you are familiar with the YAML format. Otherwise you can use the `sos config` command to add or modify settings. For example, command\n",
    "\n",
    "```bash\n",
    "sos config --global --set hosts.shark.address username@shark.com\n",
    "```\n",
    "\n",
    "would write to `~/.sos/config.yml` the following content\n",
    "\n",
    "```yml\n",
    "hosts:\n",
    "    shark:\n",
    "        address: username@shark.com\n",
    "```\n",
    "\n",
    "This effectively defines a host with alias `shark`. All configurations related to this host should be defined under `shark`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `address`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "IP address or URL to the remote host. Name `localhost` can be used for localhost. If you have a different user name on the the remote host, specify the `address` in the format of `username@hostaddress`.\n",
    "\n",
    "Note that SoS does not support username/password authentication and you will have to set up public key authentication between local and remote hosts to  communicate with remote host."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `path_map`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[{\"output_type\":\"stream\",\"text\":\"File contains parsing errors: <string>\\n\\t[line  2]: `path_map` is a list of directory mappings between local and remote directories. For example, if you work locally on a Mac machine with home directory `/Users/myuser`, and the remote server is a Linux machine with home directory `/home/myuser`, you should define a `path_map` using command\\n\\n```\\n% sos config --global --set hosts.monster.path_map /Users/myuser/:/home/myuser/\\n```\\n\\nInvalid statements: SyntaxError('invalid syntax', ('<string>', 1, 1, '`path_map` is a list of directory mappings between local and remote directories. For example, if you work locally on a Mac machine with home directory `/Users/myuser`, and the remote server is a Linux machine with home directory `/home/myuser`, you should define a `path_map` using command\\\\n'))\\n\",\"name\":\"stderr\"}]"
   },
   "source": [
    "`path_map` is a list of directory mappings between local and remote directories. Paths in a `path_map` should be absolute path and a local path will be converted to absolute path before mapping. For example, a `path_map` \n",
    "\n",
    "```\n",
    "/Users/myuser/:/home/myuser/\n",
    "```\n",
    "would map `test/a.txt` under home directory to `/home/myuser/test/a.txt`, and map `/Users/myuser/resources` to `/home/myuser/resources`.\n",
    "\n",
    "Multiple `path_map` could be defined and a path is mapped by the first matching `path_map`. For example,\n",
    "\n",
    "```\n",
    "/Users/myuser/projects/:/home/myuser/scratch/projects/\n",
    "/Users/myuser:/home/myuser\n",
    "```\n",
    "\n",
    "will map `/Users/myuser/projects/input.fastq` to `/home/myuser/scratch/projects/input.fastq`, and `/users/myuser/a.txt` to `/home/myuser/a.txt`.\n",
    "\n",
    "The order of the map is significant and the second `path_map` in the following configuration will be ignored because it is shadowed by the first one.\n",
    "\n",
    "```\n",
    "/Users/myuser:/home/myuser\n",
    "/Users/myuser/projects/:/home/myuser/scratch/projects/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `shared`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `shared` tells SoS which file systems are shared between local and remote hosts so that it does not have to synchronize files under these directories between the hosts.\n",
    "\n",
    "You will need to\n",
    "\n",
    "* Ignore this option if the local and remote hosts does not share any file system.\n",
    "* set `shared` to `/` (root) if your local and remote host share all file systems\n",
    "* List volumes that are shared between your local and remote systems\n",
    "\n",
    "Shared file systems do not have to be mounted at the same locations. For example, a local file system `/projects` might be available at the remote host under `/scratch/projects`. In this case, you should\n",
    "\n",
    "* Set `/projects` as `shared` so that files under `/projects` will not be copied.\n",
    "* Set `/projects:/scratch/projects` in `path_map` so that the path can be correctly translated between local and remote hosts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `send_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "SoS uses `rsync` command to exchange files between hosts, and use `ssh` to execute command. If the default commands do not work for your configuration (e.g. if you do not have `rsync` and need to use `scp`, you can define options `send_cmd` (and `received_cmd` and `execute_cmd`) for your particular configuration. These variables should be defined with `${source}` and `${dest}` which will be replaced by source and destination filenames for each file.\n",
    "\n",
    "It is rather tricky to define `send_cmd` for all scenarios (files, directories, missing directory on remote host) so it is usually easier to install `rsync` and use system default `send_cmd` than defining `send_cmd` by youself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `receive_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Command to receive files from remote server. It is usually easier to install `rsync` than defining this option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `execute_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Command to execute a command on remote host. The default value should work in almost all cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Common queue configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `queue_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `query_type` determines the type of remote server or job queue. SoS currently supports the following types of job queues:\n",
    "\n",
    "1. **`process`**: this is the default queue type. Tasks are executed directly, either on local host or on a server.\n",
    "2. **`pbs`**: A PBS/MOAB cluster system where tasks are submitted using commands such as `qsub`.\n",
    "3. **`rq`**: A redis queue where tasks are submitted to the rq server and monitored through rq-dashboard.\n",
    "4. **`celery`**: A celery queue where tasks are submitted to the celery server and monitored through celery's flower module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `status_check_interval`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `status_check_interval` determines frequency at which SoS checks status of jobs. This is set by default to 2 seconds for `process` queue type, and `10` seconds for all other types. This number should be set to at least `60` for remote servers and longer jobs because it can be a burden to query the status of jobs very frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `max_running_jobs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Maximum number of running jobs. This setting controls how SoS releases tasks to job queues and is independent of possible maximum running job settings of individual task queues.\n",
    "\n",
    "This option is set to 10 by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Arbitrary key value pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "You can define arbitrary key value pairs in the host configuration. These variables could be used for the interpolation of commands and templates. For example, if you define\n",
    "\n",
    "```yml\n",
    "queue: long\n",
    "```\n",
    "\n",
    "You could use \n",
    "\n",
    "```bash\n",
    "#PBS -q ${queue}\n",
    "```\n",
    "\n",
    "in your PBS job templates (configuration `template_file` or `job_template`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## RQ configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `redis_host`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Address of the redis server, default to `localhost`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `redis_port`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Port of the redis server, default to `6379`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Celery configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `broker`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "output_cache": "[]"
   },
   "source": [
    "`broker` configuration of celery app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `backend`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "output_cache": "[]"
   },
   "source": [
    "`backend` configuration of the celery app."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## PBS/Torch configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `template_file`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "`template_file` should point to the location of a template file (available locally, not on remote host) that will be used to generate a shell script that will be submitted to the PBS system. A typical template would look like\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#PBS -N ${task}\n",
    "#PBS -l nodes=${nodes}:ppn=${ppn}\n",
    "#PBS -l walltime=${walltime}\n",
    "#PBS -l mem=${mem}\n",
    "#PBS -o ${cur_dir}/${task}.out\n",
    "#PBS -e ${cur_dir}/${task}.err\n",
    "#PBS -q long\n",
    "#PBS -m ae\n",
    "#PBS -M your@email.address\n",
    "#PBS -v ${cur_dir}\n",
    "\n",
    "cd ${cur_dir}\n",
    "\n",
    "sos execute ${task} -v ${verbosity} -s ${sig_mode} ${'--dryrun' if run_mode == 'dryrun' else ''}\n",
    "```\n",
    "\n",
    "The template file will be interpolated with the following information\n",
    "\n",
    "* `task`: task id\n",
    "* `nodes`, `ppn`, `walltime`, `mem`: resource task options\n",
    "* `cur_dir`:  current project directory, which will be translated to path in remote host if the task is executed remotely\n",
    "* `verbosity` and `sig_mode`: sos run mode.\n",
    "* `run_mode` to allow the script to be executed in dryrun mode, in which mode scripts would be printed instead of executed. It is very important to set this option because the job script would be executed directly (on head node) instead of sent to the PBS queue if sos is running in dryrun mode (`sos run -q pbs -n`).\n",
    "* Other key/value pairs you defined for the server\n",
    "\n",
    "Note that\n",
    "1. You will need to specify resource options (`nodes`, `ppn`, `walltime`, and `mem`) as task options if they are used in the template file.\n",
    "2. If you need to specify more options (e.g. queue name), you will have to define multiple host entries with different options. For example, you could define two queue entries as `cluster-short` and `cluster-long` for two queues on the same cluster. These two entries could share the same template file but different `queue: name` values.\n",
    "3. An often forgotten feature is that SoS string interpolation accepts arbitrary Python expressions so it is possible to specify `queue` by `walltime`, using expressions such as \n",
    "\n",
    "```\n",
    "${'long' if walltime > 60*60*24*5 else 'short'}\n",
    "```\n",
    "\n",
    "Note that walltime would be an integer internally even if it is specified in the format of `HH:MM:SS` in the script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `job_template`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "`job_template` should be the content of the template file if you prefer listing the content directly in the config file, and happen to know how to specify multi-line strings in YAML format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `submit_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "A `submit_cmd` template is the command that will be executed to submit the job. It accepts the same set of variables as `job_template`, with an additional variable `job_file` pointing to the location of the job file on the remote host. The `submit_cmd` is usually as simple as\n",
    "\n",
    "```bash\n",
    "qsub ${job_file}\n",
    "```\n",
    "\n",
    "but you could specify some options from command line instead of the job file and define `submit_cmd` as\n",
    "\n",
    "```bash\n",
    "msub -l ${walltime} < ${job_file}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `status_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "An command to query the status of a submitted task. For a standard PBS system, this option could be\n",
    "\n",
    "```\n",
    "qstat ${job_id}\n",
    "```\n",
    "\n",
    "where `job_id` is the output of command `submit_cmd`. The `status_cmd` is interpolated with variables `job_id` (PBS job ID), `task` (SoS task id), and `verbosity` (command line verbosity level) so you would adjust options for different verbosity level (e.g. `${'-f' if verbosity > 2 else ''}`).\n",
    "\n",
    "Note that the `status_cmd` is only called with `-v 2` or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `kill_cmd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "A command to kill a submitted job on the cluster. For a standard PBS system, this option could be\n",
    "\n",
    "```\n",
    "qdel ${job_id}\n",
    "```\n",
    "where `job_id` is the output of command `submit_cmd`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Resource options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The resource options will be sent to individual task queues in appropriate format. You do not have to specify all options because task queues can support a subset of these options and some task queues provide default values (and some do not). It is however generally a good idea to specify them all so that your tasks could be executed on all types of task queues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `walltime`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Estimated maximum running time of the task. This parameter will be sent to different task queues and it is up to the task queue to decide if the task would be killed if the task could not be completed within specified `walltime`. `walltime` could be specified\n",
    "\n",
    "1. As an integer number (in seconds).\n",
    "2. As a string in the format of `HH:MM:SS` where `HH`, `MM` and `SS` are hours, minutes, and seconds. For example, you could use `walltime=240:00:00` for a job that would run 10 days.\n",
    "\n",
    "SoS automatically converts this option to an integer and formats it appropriately for different task engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `nodes`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Number of computing nodes requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `ppn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Number of processes on each computing node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `mem`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The total amount of memory needed across all nodes. Default units are bytes; can also be expressed in megabytes (`mem=4000MB`). gigabytes (`mem=4GB`) or gibibytes (`mem=4GiB`), although all inputs would be converted to bytes internally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Execution options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `queue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `queue` specifies a task queue to which the current task will be submitted. This option overrides system default (command line option `-q`) so it is generally a good idea to use command line option `-q` so that the task could be submitted to different task queues, unless the task has to be executed in a particular server (e.g. with a software that is unavailable elsewhere)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `preserved_vars`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "All variables in the task context environment, including implicit SoS variables such as `_input` and `_output` are automatically translated if they are string or sequence of strings (list, tuple etc). This would however translate variables such as `sample_name` with value `my_sample` to something like `/home/myuser/project/my_sample`. It is therefore important for you to identify all variables that should be preserved during context-switching in the option `preserved_vars`.\n",
    "\n",
    "This variables takes a list of variable names, but a string can be specified if there is only one name. That is to say, both\n",
    "\n",
    "```\n",
    "preserved_vars='sample_name'\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "preserved_vars=['sample_name', 'title']\n",
    "```\n",
    "\n",
    "are acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option `workdir`\n",
    "\n",
    "Default to current working directory.\n",
    "\n",
    "Option `workdir` controls the working directory of the task. For example, the following step downloads a file to the `resource_dir` using command `wget`.\n",
    "\n",
    "```python\n",
    "[10]\n",
    "\n",
    "task: workdir=resource_dir\n",
    "\n",
    "run:\n",
    "  wget a_url -O filename\n",
    "```\n",
    "\n",
    "Runtime option `workdir` will be translated to remote host if the task is executed remotely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option `concurrent`\n",
    "\n",
    "Default to `True`.\n",
    "\n",
    "If the step process is repeated for multiple input groups (using input options `group_by` or `for_each`), all loop processes will by default be sent to the task engine to be executed in parallel (subject to `max_running_jobs` of individual task queue). If your tasks are sequential in nature (e.g. the next input group depends on the result of the current input group), you can set `concurrent=False`, in which case the next task will be generated and sent to the task queue only after the current one has been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option `env`\n",
    "\n",
    "The `env` option allow you to modify runtime environment, similar to the `env` parameter of the `subprocess.Popen` function. For example, you can execute your command with in a specific directory using\n",
    "\n",
    "```sos\n",
    "task:  env={'PATH': '/path/to/mycommand' + os.sep + os.environ['PATH']}\n",
    "run:\n",
    "   mycommand \n",
    "```\n",
    "\n",
    "Option `env` is NOT translated to remote host because it is of type directionay. The job template is usually a good place to set host-specific environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option `prepend_path`\n",
    "\n",
    "Option `prepend_path` is a shortcut to option `env` to prepend one (a string) or more (a list of strings) paths to system path. For example, the above example can be shortened to\n",
    "\n",
    "```sos\n",
    "task:  prepend_path='/path/to/mycommand'\n",
    "run:\n",
    "   mycommand \n",
    "```\n",
    "\n",
    "Option `prepend_path` is NOT translated to remote host because it is likely to be host specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### Option `active`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `active` specifies the active task within a input loop. It should be an index or a list of indexes when the task will be executed. Negative index is acceptable (e.g. task for only the last input loop will be executed with `active=-1`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "## Commands and Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `sos run -q`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The `-q` option of command `sos run` (or `sos-runner`) sets the default task queue for all tasks. For example,\n",
    "\n",
    "```bash\n",
    "sos run myscript -q shark\n",
    "```\n",
    "\n",
    "would send all tasks in workflow `default` defined in `myscript.sos` to a task queue `shark`, with detailed information about `shark` defined in either global `~/.sos/config.yml` or local (`./config.yml`) formats. You can also save configurations to other configuration files and specify them using option `-c`. E.g.\n",
    "\n",
    "```bash\n",
    "sos run myscript -q shark -c shark.yml\n",
    "```\n",
    "\n",
    "Note that this option does not override option `queue` of steps so you could send some tasks to specific queues and all others to the default queue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `dryrun` mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "The dryrun running mode is very useful in checking if your scripts are correctly translated and if your machine settings are correct. **It is strongly recommended that you execute your script in dryrun mode before submitting them to remote hosts and/or task queues**.\n",
    "\n",
    "How tasks are executed depends a bit on your configuration but basically,\n",
    "\n",
    "1. For local tasks (`process` task engine), the tasks are executed directly with `sos execute task -n` (`-n` for dryrun mode).\n",
    "\n",
    "2. For direct remote execution (e.g. `sos run script -q server -n` with `queue_type` set to `process` (default)), the tasks will be generated and copied to the remote server, and will be executed with command `sos execute task -n`.\n",
    "\n",
    "3. For submitting to a PBS task queue (e.g. `sos run script -q pbs -n` with `queue_type` set to `pbs`), the tasks will be generated, copied to remote host. Job files will also be generated according to `template_file` or `job_template` and will be copied to the remote host. However, instead of using `submit_cmd` to submit the job to the PBS queue, **the job script will be executed directly on the head node**. It is therefore important for you to allow the jobs to be run in `dryrun` mode and complete in seconds. Otherwise your system admin would hunt you for running large jobs directly on head nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `sos status`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command \n",
    "\n",
    "```bash\n",
    "sos status [tasks] -q query\n",
    "```\n",
    "checkes the status of tasks. You can specify any number of first characeters of a task to specify a task, for example,\n",
    "\n",
    "```bash\n",
    "sos task 7\n",
    "sos task 77e\n",
    "sos task 7736e\n",
    "```\n",
    "would all work for a task with ID `77e36e7404cf6c2ef7079a09e84a4d6d`, but multiple tasks could be identifies if they share the same leading digits. Actually, \n",
    "\n",
    "```\n",
    "sos task \n",
    "```\n",
    "would match all tasks and list the status of all local tasks.\n",
    "\n",
    "Option `-q` specifies the task queue to monitor. It will login to a remote host if the tasks are executed on a remote server. For example,\n",
    "\n",
    "```\n",
    "sos status -q docker\n",
    "```\n",
    "\n",
    "would check the status of all tasks on a remote host `docker`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `sos status -v -q`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Option `-v` controls the details of the output of command `sos status`. For example,\n",
    "\n",
    "```\n",
    "sos status e7404cf6c2 -v0\n",
    "```\n",
    "would print just the status of the task (e.g. `running`).\n",
    "\n",
    "```\n",
    "sos task 77e -v1\n",
    "```\n",
    "would print the task id and their status\n",
    "\n",
    "```\n",
    "77e36e7404cf6c2ef7079a09e84a4d6d    running\n",
    "77e3c2ef7079a236e7404cf6c2f343d3    completed\n",
    "```\n",
    "\n",
    "Option `-v0` and `-v1` could check the status of multiple tasks, as realized by SoS. Some tasks queues have their own task status command and option `-v2` (and upper) will use these commands (if specified) to check the status of the jobs. That is to say\n",
    "\n",
    "``` bash\n",
    "sos task 77e36 -v2\n",
    "```\n",
    "\n",
    "might return output of a command\n",
    "\n",
    "```\n",
    "qstat 18433\n",
    "```\n",
    "\n",
    "if the task has been submitted to a cluster named `shark` with a job id `18433`.\n",
    "\n",
    "If you would like to know more about the tasks,\n",
    "\n",
    "```bash\n",
    "sos task 77e36 -v3\n",
    "```\n",
    "\n",
    "would list the script the task is running and all variables in abbreviated format, and\n",
    "\n",
    "```bash\n",
    "sos task 77e36 -v4\n",
    "```\n",
    "would list all variables in complete form.\n",
    "\n",
    "Finally, using `-q` in combination with `-v` allows you to list the variables used in remote server.\n",
    "\n",
    "```bash\n",
    "sos task 77e36 -v4 -q linux\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `sos kill` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Command\n",
    "\n",
    "```bash\n",
    "sos kill [tasks] [-q queue]\n",
    "```\n",
    "\n",
    "kills specified or all tasks on specified job queue `queue`. Because the same job could be executed on different queues (you have have done so), you will have to specify the correct queue name to kill the job on different queues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### `sos execute`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "Command \n",
    "````\n",
    "sos execute [tasks] [-q queue]\n",
    "```\n",
    "\n",
    "is the command that is used internally by `sos run` to execute tasks but you could use this command to execute tasks externally. For example, if a task failed on a server, you could use command\n",
    "\n",
    "```\n",
    "sos execute task_id -q server\n",
    "```\n",
    "\n",
    "to execute the command on another server. Note that `task_id` specifies a local task with local paths. The task will be converted to a remote task (with path names converted for that host) if `server` specifies a remote host. This makes it easy for you to re-submit tasks to the same server after changing server configuration, or submit the same task to a different server. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "output_cache": "[]"
   },
   "source": [
    "### Remote execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "### PBS Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Host configuration\n",
    "\n",
    "`~/.sos/config.yml`\n",
    "\n",
    "```yml\n",
    "hosts:\n",
    "  nautilus:\n",
    "    address: mdarisngc03.mdanderson.edu\n",
    "    path_map:\n",
    "    - /Users/bpeng1:/scratch/bcb/bpeng1\n",
    "    queue_type: pbs\n",
    "    status_check_interval: 30\n",
    "    template_file: ~/.sos/HPC.tmpl\n",
    "    max_running_jobs: 100\n",
    "    submit_cmd: msub ${job_file}\n",
    "    status_cmd: qstat ${job_id}\n",
    "    kill_cmd: qdel ${job_id}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "#### Job template\n",
    "\n",
    "`~/.sos/HPC.tmpl:`\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#PBS -N ${task}\n",
    "#PBS -l nodes=${nodes}:ppn=${ppn}\n",
    "#PBS -l walltime=${walltime//3600}:${walltime/60%60}:${walltime%60}\n",
    "#PBS -l mem=${mem//1000000}GB\n",
    "#PBS -o ${cur_dir}/${task}.out\n",
    "#PBS -e ${cur_dir}/${task}.err\n",
    "#PBS -m ae\n",
    "#PBS -M bpeng@mdanderson.org\n",
    "#PBS -v ${cur_dir}\n",
    "\n",
    "cd ${cur_dir}\n",
    "\n",
    "sos execute ${task} -v ${verbosity} -s ${sig_mode} ${'--dryrun' if run_mode=='dryrun' else ''}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test script\n",
    "\n",
    "```\n",
    "[10]\n",
    "input: for_each={'tid': range(10) }\n",
    "\n",
    "task: concurrent=True, walltime='00:20:00', mem='100M', nodes=1, ppn=1\n",
    "\n",
    "run:\n",
    "    echo I am task ${tid}\n",
    "    sleep ${60  * (tid + 1)}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "output_cache": "[]"
   },
   "source": [
    "#### Commands\n",
    "\n",
    "```\n",
    "sos run test -q nautilus\n",
    "sos status -q nautilus\n",
    "sos kill cb1 -q nautilus\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "output_cache": "[]"
   },
   "source": [
    "It can be tricky to get everything working but you only need to do this once for each server or task queue that you would like to use. After that, you are free to submit your tasks to any of the servers without worrying about different file systems, task queues etc. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos.jupyter.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "celltoolbar": true,
   "kernels": [
    [
     "sos",
     "SoS",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   }
  },
  "toc": {
   "nav_menu": {
    "height": "172px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
